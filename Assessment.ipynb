{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loyal Software Engineering, ML assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a technical assessment for the Machine Learning Software Engineer Role at Loyal Health. In this assessment, you will be expected to (1) prepare training, validation, and test data, (2) train an intent classification model with the architecture of your choice, and (3) evaluate the performance of your model. You are free to use any external libraries just be sure to update the requirements.txt with the needed libraries. Please do not use any external datasets or knowledge-bases. We expect that this assessment should take around three hours. The goal of this assessment is simply to test your ability to quickly go from limited data to a working model. We don't expect your model to be perfect, so please try to calibrate your efforts accordingly. More broadly, we will evaluate this assessment based on your code structure/readability, model performance, model evaluation procedure, system design explanations, and creativity. There are many acceptable ways to approach this assessment, so please feel free to take some creative liberties. Best of luck! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, be sure to have conda installed on your machine. If you do not have conda installed, please follow the instructions __[here](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html)__ . With conda installed we will create a conda environment using python 3.7 as follows:\n",
    "\n",
    "<code><center>conda create --name LoyalEnv python=3.7</center></code>\n",
    "\n",
    "With the environment (LoyalEnv) created you may now activate it by using the following command in your terminal:\n",
    "\n",
    "<code><center>conda activate LoyalEnv</center></code>\n",
    "\n",
    "Next to run this with jupyter in your terminal with the environment activated you will install ipykernel:\n",
    "\n",
    "<code><center>conda install ipykernel</center></code>\n",
    "\n",
    "Now, from the terminal run the command <code>pip install -r requirements.txt</code> to install the required libraries or by uncommenting and running the first code block of the imports section. If you have trouble getting conda working in the Jupyter Notebooks, __[this](https://towardsdatascience.com/get-your-conda-environment-to-show-in-jupyter-notebooks-the-easy-way-17010b76e874)__ article may be helpful. You are not required to use a conda environment as specified for your model development, but be aware that creating a conda environment with the specifications of your requirements.txt file will be how we run your code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets==1.18.4 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.18.4)\n",
      "Requirement already satisfied: packaging in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (20.4)\n",
      "Requirement already satisfied: multiprocess in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (0.70.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (1.22.3)\n",
      "Requirement already satisfied: dill in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (0.3.4)\n",
      "Requirement already satisfied: pandas in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (1.4.2)\n",
      "Requirement already satisfied: aiohttp in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (2.24.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (4.64.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from datasets==1.18.4->-r requirements.txt (line 1)) (2022.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from packaging->datasets==1.18.4->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from packaging->datasets==1.18.4->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.4->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: pyyaml in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.4->-r requirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: filelock in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==1.18.4->-r requirements.txt (line 1)) (3.0.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from pandas->datasets==1.18.4->-r requirements.txt (line 1)) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from pandas->datasets==1.18.4->-r requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.4->-r requirements.txt (line 1)) (2.0.12)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.4->-r requirements.txt (line 1)) (19.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.4->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.4->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.4->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.4->-r requirements.txt (line 1)) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->datasets==1.18.4->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from responses<0.19->datasets==1.18.4->-r requirements.txt (line 1)) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.4->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.4->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.18.4->-r requirements.txt (line 1)) (2020.6.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (4.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: requests in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: sacremoses in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: six in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.20.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from torch) (4.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_hub in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow_hub) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow_hub) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_text in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (2.8.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow_text) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow_text) (2.8.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow-hub>=0.8.0->tensorflow_text) (1.22.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (4.2.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.10.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.5.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.24.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (13.0.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: setuptools in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (49.2.0.post20200714)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.11.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorflow<2.9,>=2.8.0->tensorflow_text) (1.44.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.34.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.6.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.11.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.25.11)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/m31418/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow_text) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Provided Imports\"\"\"\n",
    "from datasets import load_dataset\n",
    "\n",
    "\"\"\"Your Imports\"\"\"\n",
    "from transformers import BertTokenizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tensorflow.keras import datasets, layers, models, callbacks\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have provided you with code to load the train, validation, and test data from the Huggingface datasets library. We have also provided you with \n",
    "several thousand unlabeled data points from the same distribution. Feel free to leverage these in any way you like. If you so desire, you can create your own dataset object using any library you like from what we have provided.We just ask that you do not do any hand labeling of the data. Using as many blocks as you like, do any data preprocessing you wish to prepare the data for ingestion into your model. Briefly rationalize any data preparation steps in a markdown block or comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration christianloyal--loyal_clinc_MLE-0661c385abbfe8c6\n",
      "Reusing dataset csv (/Users/m31418/.cache/huggingface/datasets/csv/christianloyal--loyal_clinc_MLE-0661c385abbfe8c6/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15aaca4a91f84b25962dfd2b8febdd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2956\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 4500\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "labeled_data = load_dataset(\"christianloyal/loyal_clinc_MLE\")\n",
    "print(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489\n"
     ]
    }
   ],
   "source": [
    "#Create pandas dataframes containing the training, validation, and test sets\n",
    "train = pd.DataFrame.from_dict(labeled_data[\"train\"])\n",
    "val = pd.DataFrame.from_dict(labeled_data[\"validation\"])\n",
    "test = pd.DataFrame.from_dict(labeled_data[\"test\"])\n",
    "\n",
    "correct_size = int(((len(train.index)+len(val.index))*3)/4)\n",
    "to_move = val.sample(correct_size - len(train.index))\n",
    "\n",
    "train = pd.concat([train, to_move], ignore_index=True)\n",
    "val = val.drop(to_move.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "card_declined         89\n",
       "sync_device           89\n",
       "next_song             89\n",
       "apr                   89\n",
       "shopping_list         88\n",
       "                      ..\n",
       "directions            53\n",
       "credit_score          52\n",
       "distance              52\n",
       "cancel_reservation    52\n",
       "share_location        52\n",
       "Name: label, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the distribution of classes within the training set\n",
    "all_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration christianloyal--loyal_clinc_MLE_unlabeled-25971229c07b1588\n",
      "Reusing dataset csv (/Users/m31418/.cache/huggingface/datasets/csv/christianloyal--loyal_clinc_MLE_unlabeled-25971229c07b1588/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e05c07cbf24453a1608fbf9b3a3330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unlabeled_data = load_dataset(\"christianloyal/loyal_clinc_MLE_unlabeled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer=LabelBinarizer()\n",
    "\n",
    "trainfeatures=train.copy()\n",
    "trainlabels=trainfeatures.pop(\"label\")\n",
    "trainfeatures=trainfeatures.values\n",
    "trainlabels=binarizer.fit_transform(trainlabels.values)\n",
    "\n",
    "testfeatures=test.copy()\n",
    "testlabels=testfeatures.pop(\"label\")\n",
    "testfeatures=testfeatures.values\n",
    "testlabels=binarizer.transform(testlabels.values)\n",
    "\n",
    "validfeatures=val.copy()\n",
    "validlabels=validfeatures.pop(\"label\")\n",
    "validfeatures=validfeatures.values\n",
    "validlabels=binarizer.transform(validlabels.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the tokenizer and set the max length of input samples\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "MAX_LENGTH = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution between training, validation, and test sets seemed off to me; it seemed more appropriate to me that the data follow a 7:2:1 split between training, validation, and test samples. For the purposes of consistency across assessment, I decided to leave the test set alone. However, I rebalanced the sizes of the training and validation sets to better reflect a 75:25 split. While perusing the data I also noticed that there is a severe imbalance in the classes. This may not present a large problem as long as each class is still represented in the training data and the test data reflects the training data, however this is an issue that could be solved either with minority-oversampling, majority-undersampling, or synthetic data generation. Furthermore, unlabeled data could be used to pretrain a model such as Bert to make it more domain specific, or could be used along with the labeled data to train a GAN whose discriminator model is ultimately used to make predictions. Due to time constraints, these solutions were not explored further in this iteration of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you may use as many code blocks as you please for the training of your model. As a tip, if you wish to run your training on a hardware accelerated device feel free to run this notebook on one of __[Google Colab](https://colab.research.google.com/)__'s free machines. We have set up our environment for this assignment to best replicate the environment of Colab machines for minimal difficulty in leveraging these resources. Feel free to use the validation set for any tuning, but just be sure that none of the validation data is used directly as training data in addition to the training set. Also, refrain from using any of the test data for model tuning. It may also be helpful to set a random seed or using anything else that will improve model reproducibility. In writing, briefly rationalize any architectural or or procedural decisions via a markdown block or comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3'\n",
    "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(300, activation='sigmoid', name='Dense_Layer_1')(net)\n",
    "    net = tf.keras.layers.Dense(150, activation='softmax', name='Dense_Layer_2')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'encoder_outputs':  108310273   ['preprocessing[0][0]',          \n",
      "                                 [(None, 128, 768),               'preprocessing[0][1]',          \n",
      "                                 (None, 128, 768),                'preprocessing[0][2]']          \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 768)          0           ['BERT_encoder[0][13]']          \n",
      "                                                                                                  \n",
      " Dense_Layer_1 (Dense)          (None, 300)          230700      ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " Dense_Layer_2 (Dense)          (None, 150)          45150       ['Dense_Layer_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,586,123\n",
      "Trainable params: 108,586,122\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model = build_classifier_model()\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "metrics = [tf.metrics.CategoricalAccuracy(), f1_score, precision, recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true) \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    all_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    recall = true_positives / (all_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = K.ones_like(y_true) \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    \n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "optimizer=tf.keras.optimizers.Adam()\n",
    "classifier_model.compile(optimizer=optimizer,\n",
    "                         loss=loss,\n",
    "                         metrics=metrics,\n",
    "                        )\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 5, \n",
    "                                        restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 2884s 81s/step - loss: 5.0409 - categorical_accuracy: 0.0092 - val_loss: 5.1142 - val_categorical_accuracy: 0.0067\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 2836s 81s/step - loss: 4.9714 - categorical_accuracy: 0.0081 - val_loss: 5.0923 - val_categorical_accuracy: 0.0067\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 2756s 79s/step - loss: 4.9659 - categorical_accuracy: 0.0125 - val_loss: 5.1006 - val_categorical_accuracy: 0.0060\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 2704s 77s/step - loss: 4.9557 - categorical_accuracy: 0.0078 - val_loss: 5.0985 - val_categorical_accuracy: 0.0054\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 2674s 77s/step - loss: 4.9514 - categorical_accuracy: 0.0094 - val_loss: 5.1092 - val_categorical_accuracy: 0.0047\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 2668s 76s/step - loss: 4.9513 - categorical_accuracy: 0.0087 - val_loss: 5.1039 - val_categorical_accuracy: 0.0034\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 2648s 76s/step - loss: 4.9494 - categorical_accuracy: 0.0094 - val_loss: 5.1054 - val_categorical_accuracy: 0.0067\n"
     ]
    }
   ],
   "source": [
    "history = classifier_model.fit(x=trainfeatures,y=trainlabels,\n",
    "                               validation_data=(validfeatures,validlabels),\n",
    "                               batch_size=128,\n",
    "                               epochs=epochs,\n",
    "                              callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of the data occurs within the model as part of the first layer, handled by a version of Bert from Tfhub. This layer produces token id as well as attention mask and token type information. Then, these inputs are encoded by Bert, and the pooled output is taken. A dropout rate of .2 is applied to prevent overfitting before the output is then fed through two dense layers. The second dense layer was decided on after experimentation showed that just one dense layer was unable to capture the nuances of differences in the input, especially given the large number of classes. In another version, a convolutional layer could be used to capture information specific to the sequences of tokens. Because the true classes of the data have been converted to one-hot vectors, Categorical Cross Entropy is used as the loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we ask that you evaluate the performance of your model on the provided test set. The metric that you choose to use is up to you, but please explain your choice. When evaluating your model, keep in mind that we have a hold out test set of our own, so overfitting to the test set should be avoided. Briefly explain your choices in evaluating and assess the performance of your model. Explain the good and the bad and talk about how the model could be improved in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, \n",
    "accuracy, \n",
    "f1_score, precision, recall = classifier_model.evaluate(testfeatures,testlabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats on completing the assessment. Now, all we ask is that you create a private repository on Github with your Assessment.ipynb and requirements.txt file and share that with us. Feel free to add any additional details you like in the readme file. We would also appreciate it if you linked us to any relevant coding projects on Github via the readme file or in the provided markdown block below. Thanks for your interest in Loyal!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Add any additional notes or external links here. *** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "metadata": {
   "interpreter": {
    "hash": "cfae51942708c3f98ecc293602f1a6110eaf1fc63935f2e7a4e8f97e53ac4546"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
